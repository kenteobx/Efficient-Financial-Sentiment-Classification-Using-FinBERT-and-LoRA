# Efficient Financial Sentiment Classification Using FinBERT and LoRA
 This repository contains the implementation and report for the project “Parameter-Efficient Fine-Tuning of FinBERT for Financial Sentiment Classification.”  The project fine-tunes FinBERT on the Financial PhraseBank (AllAgree) dataset to classify financial news sentences as positive, neutral, or negative.  Two fine-tuning strategies are compared:  Full Fine-Tuning – all model parameters updated.  LoRA (Low-Rank Adaptation) – parameter-efficient fine-tuning updating only ~1 % of parameters.  The repository includes:  Data preprocessing and exploratory analysis (label distribution, word clouds)  Baseline model using TF-IDF + Logistic Regression  Transformer fine-tuning with Hugging Face Trainer API  Evaluation metrics (Accuracy, Macro-F1, ROC-AUC, PR-AUC)  Efficiency analysis (parameter counts, training time)  Error analysis and discussion of model behaviour  Results show that LoRA achieves near-parity performance with Full Fine-Tuning while using 98.8 % fewer trainable parameters, making it ideal for resource-constrained financial NLP applications.
